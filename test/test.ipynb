{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from dotenv import load_dotenv\n",
    "from typing import List, Tuple, Annotated, Sequence, Literal\n",
    "from typing_extensions import TypedDict\n",
    "from IPython.display import Image, display\n",
    "import psycopg2\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OLLAMA_MODEL = \"llama3.1:8b\"\n",
    "POSTGRES_PASSWORD = os.getenv(\"POSTGRES_PASSWORD\")\n",
    "POSTGRES_USER = os.getenv(\"POSTGRES_USER\")\n",
    "POSTGRES_DATABASE = os.getenv(\"POSTGRES_DATABASE\")\n",
    "\n",
    "OLLAMA_BASE_URL = \"100.110.219.100:11434\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(model=OLLAMA_MODEL, temperature=0, base_url=OLLAMA_BASE_URL)\n",
    "llm_json = ChatOllama(model=OLLAMA_MODEL, temperature=0, format=\"json\", base_url=OLLAMA_BASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_query': 'accept'}"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Router\n",
    "\n",
    "ROUTER_INSTRUCTIONS = '''You are an expert at determining whether a user question requires access to a database from a smartphone shop. \n",
    "\n",
    "The database schema is as follows:\n",
    "- id (int): The unique identifier of the smartphone. You will not use this.\n",
    "- brand (str): The brand of the smartphone, (eg. 'Apple', 'Google', 'Samsung'...)\n",
    "- model (str): The model of the smartphone (eg. 'iPhone 13 Pro Max', 'Galaxy S21 Ultra', 'Mi 13 Pro'...)\n",
    "- price (int): The price of the smartphone in Singapore Dollars.\n",
    "- stock_status (str): The stock status of the smartphone ('In Stock', 'Out of Stock')\n",
    "\n",
    "For questions related to a smartphone's price or availibility, you should accept the user query since it requires information from the database. For unknown brands or models, you should also approve the query since it may require database access. For all other questions that do not require database access, please reject the query.\n",
    "\n",
    "Return JSON with a single key user_query, that is 'accept' or 'reject' depending on whether the question requires database access.'''\n",
    "\n",
    "question = [HumanMessage(content=\"Hello, what is the price of the iphone 13 mini?\")]\n",
    "\n",
    "test_router_response = llm_json.invoke([SystemMessage(content=ROUTER_INSTRUCTIONS)] + question)\n",
    "\n",
    "json.loads(test_router_response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def executePostgreSQLQuery(query: str) -> List[Tuple[int, str, str, int, str]]:\n",
    "    '''Executes a PostgreSQL query and returns the result as a list of tuples. Please only query the table \"smartphones\".\n",
    "    \n",
    "    Args:\n",
    "        query (str): The PostgreSQL query to be executed.\n",
    "        \n",
    "    Returns:\n",
    "        result (List[Tuple[int, str, str, int, str]]): The result of the query, a list of tuples (id, brand, model, price, stock_status).\n",
    "    '''\n",
    "\n",
    "    # Connect to database\n",
    "    # print(\"executePostgreSQLQuery tool called!\")\n",
    "    conn = psycopg2.connect(database=POSTGRES_DATABASE, user=POSTGRES_USER, password=POSTGRES_PASSWORD, host=\"localhost\", port=\"5432\")\n",
    "    # print(\"Database connected successfully.\")\n",
    "    with conn.cursor() as cursor:\n",
    "        try:\n",
    "            # print(\"Executing sql query...\")\n",
    "            cursor.execute(query)\n",
    "            result = cursor.fetchall()\n",
    "        except:\n",
    "            # print(\"Error executing query.\")\n",
    "            conn.close()\n",
    "            return\n",
    "    # Close connection\n",
    "    conn.close()\n",
    "    if result:\n",
    "        # print(\"Database query success\")\n",
    "        return result\n",
    "    else:\n",
    "        return \"No results found.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[[10, \"Apple\", \"iPhone 13 Mini\", 999, \"Out of Stock\"]]'"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Database query\n",
    "\n",
    "SQL_AGENT_INSTRUCTIONS = '''You are an agent designed to interact with a PostgreSQL database.\n",
    "\n",
    "Given an input question, create a syntactically correct PostgreSQL query to run. Your query should always begin with \"SELECT * FROM smartphones WHERE\" and you can add any conditions you want. Note that all string comparisons should be match case-insensitive and enclosed within single quotes.\n",
    "\n",
    "DO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\n",
    "\n",
    "The database schema is as follows:\n",
    "- id (int): The unique identifier of the smartphone. You will not use this.\n",
    "- brand (str): The brand of the smartphone, (eg. 'Apple', 'Google', 'Samsung'...)\n",
    "- model (str): The model of the smartphone (eg. 'iPhone 13 Pro Max', 'Galaxy S21 Ultra', 'Mi 13 Pro'...)\n",
    "- price (int): The price of the smartphone in Singapore Dollars.\n",
    "- stock_status (str): The stock status of the smartphone ('In Stock', 'Out of Stock')\n",
    "'''\n",
    "\n",
    "\n",
    "question = [HumanMessage(content=\"Hello, what is the price of the iphone 13 mini?\")]\n",
    "\n",
    "llm_with_db = llm.bind_tools([executePostgreSQLQuery])\n",
    "\n",
    "test_sql_agent_response = llm_with_db.invoke([SystemMessage(content=SQL_AGENT_INSTRUCTIONS)] + question)\n",
    "\n",
    "tool_call_result = executePostgreSQLQuery.invoke(test_sql_agent_response.tool_calls[0]).content\n",
    "\n",
    "tool_call_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'llama3.1:8b', 'created_at': '2025-03-17T07:40:44.7963767Z', 'done': True, 'done_reason': 'stop', 'total_duration': 427010995, 'load_duration': 27766612, 'prompt_eval_count': 457, 'prompt_eval_duration': 24000000, 'eval_count': 37, 'eval_duration': 374000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-3f1da5b1-b757-4fe6-afe9-a475c05fdf2c-0', tool_calls=[{'name': 'executePostgreSQLQuery', 'args': {'query': \"SELECT * FROM smartphones WHERE brand = 'Apple' AND model = 'iPhone 13 Mini'\"}, 'id': '0eea0b14-665b-4cbf-b107-5444accd1eca', 'type': 'tool_call'}], usage_metadata={'input_tokens': 457, 'output_tokens': 37, 'total_tokens': 494})"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sql_agent_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have an iPhone 13 Mini available in our database. The price for this model is $999. However, we currently do not have it in stock.\n",
      "\n",
      "If you're interested in purchasing a similar device, I can suggest considering other models such as the iPhone 13 or checking back with us when new stock arrives.\n"
     ]
    }
   ],
   "source": [
    "# Generate response\n",
    "\n",
    "RAG_PROMPT = '''You are an assistant that helps to answer users' queries about smartphone pricing and availibility.\n",
    "Here is the context to use to answer the question, a database query response that contains ONLY information about the requested smartphone(s) brand, model, price, and availibility. \n",
    "If the requested smartphone is not found in the database, please inform the user that you do not sell this model.\n",
    "For all other specifications like storage, colour, etc. please inform the user that you do not have the information. \n",
    "Inform the user politely instead of giving incorrect data, suggesting alternative models instead. Offer suggestions if customers type incomplete or ambiguous queries (e.g., \"Did you mean iPhone 13 Pro or iPhone 13 Mini?\"):\n",
    "\n",
    "{context} \n",
    "\n",
    "Here is the user's question:\n",
    "\n",
    "{question}\n",
    "\n",
    "Convey all information to the user.\n",
    "Answer:'''\n",
    "\n",
    "rag_prompt_formatted = RAG_PROMPT.format(context=tool_call_result, question=question)\n",
    "\n",
    "test_generate_response = llm.invoke([HumanMessage(content=rag_prompt_formatted)])\n",
    "\n",
    "print(test_generate_response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'grader_score': 'yes',\n",
       " 'justification': \"The database contains information about the iPhone 13 Mini, including its price and availability status, which matches the LLM's output.\"}"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grader\n",
    "\n",
    "GRADER_INSTRUCTIONS = '''You are an expert grader that will be provided with data from a smartphone store's database and another LLM's output. Your role\n",
    "is to spot hallucinated outputs by an LLM.\n",
    "If the database contains information that matches the LLM output, grade it as 'yes'. If there are no matching results, 'No results found' will be returned by the database.\n",
    "This means that the smartphone that the user has requested is not legitimate/not present in the smartphones' database.\n",
    "\n",
    "Example:\n",
    "{'grader_score': 'no',\n",
    " 'justification': \"The database does not contain any information about the price of the iPhone 13 Pro, so it's likely that the LLM made something up.\"}\n",
    "\n",
    "Return JSON with two keys; grader_score: either 'yes' or 'no' to indicate whether the user's question can be answered with the data provided, and\n",
    "justification: explain your rationale for grader_score.'''\n",
    "\n",
    "GRADER_PROMPT = '''Here is the data provided: \\n\\n {data} \\n\\n Here is the LLM output: \\n\\n {llm_output}'''\n",
    "\n",
    "\n",
    "grader_prompt_formatted = GRADER_PROMPT.format(data=tool_call_result, llm_output=test_generate_response.content)\n",
    "\n",
    "test_grader_response = llm_json.invoke([SystemMessage(content=GRADER_INSTRUCTIONS)] + [HumanMessage(content=grader_prompt_formatted)])\n",
    "\n",
    "json.loads(test_grader_response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm happy to help you with your query about the iPhone 13 Pro. Unfortunately, I don't have any information about this model in our database. We do not sell this specific model.\n",
      "\n",
      "However, if you're interested in purchasing an iPhone, we have other models available. For example, we have the iPhone 12 series and the latest iPhone 14 series. Would you like me to suggest some alternative options?\n"
     ]
    }
   ],
   "source": [
    "rag_prompt_formatted = RAG_PROMPT.format(context=[tool_call_result + test_grader_response.content], question=question)\n",
    "\n",
    "test_generate_response = llm.invoke([HumanMessage(content=rag_prompt_formatted)])\n",
    "\n",
    "print(test_generate_response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    tool_call_result: List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting everything above into a function\n",
    "\n",
    "# Edges\n",
    "\n",
    "def grader(state) -> Literal[\"yes\", \"no\"]:\n",
    "    '''Determines whether the results from the database can answer the user's question. If not, suggest alternatives or inform the user that the information is not available.\n",
    "    \n",
    "    Args:\n",
    "        state (State): The current state of the agent.\n",
    "    \n",
    "    Returns:\n",
    "        str: A decision by the model for whether the user's question can be answered with the data provided.'''\n",
    "    \n",
    "    llm_json = ChatOllama(model=OLLAMA_MODEL, temperature=0, format=\"json\", base_url=OLLAMA_BASE_URL)\n",
    "\n",
    "    # Take the first message in the state to get the user question\n",
    "    question = state[\"messages\"][-1].content\n",
    "\n",
    "    # Get the tool call result from the state\n",
    "    tool_call_result = state[\"tool_call_result\"]\n",
    "\n",
    "    # Format the system prompt sent to the llm with context from the database and user question\n",
    "    grader_prompt_formatted = GRADER_PROMPT.format(data=tool_call_result, question=question)\n",
    "\n",
    "    grader_response = llm_json.invoke([SystemMessage(content=GRADER_INSTRUCTIONS)] + [HumanMessage(content=grader_prompt_formatted)])\n",
    "    # print(\"Grading the results from the database...\")\n",
    "    grader_score = json.loads(grader_response.content)\n",
    "    \n",
    "    if grader_score.get(\"grader_score\") == \"yes\":\n",
    "        # print(\"The user's question can be answered with the data provided.\")\n",
    "        return \"yes\"\n",
    "    else:\n",
    "        # print(\"The user's question cannot be answered with the data provided.\")\n",
    "        return \"no\"\n",
    "\n",
    "def router(state) -> Literal[\"accept\", \"reject\"]:\n",
    "    '''Determines whether the user query requires access to the database.\n",
    "    \n",
    "    Args:\n",
    "        state (State): The current state of the agent.\n",
    "    \n",
    "    Returns:\n",
    "        str: Either calls the sql_agent node or generates a response directly based on the user query.'''\n",
    "    \n",
    "    # Take the first message in the state to get the user question\n",
    "    question = state[\"messages\"][-1]\n",
    "\n",
    "    # Get the AIResponse containing a JSON object to indicate whether database access is accepted or rejected\n",
    "    router_response = llm_json.invoke([SystemMessage(content=ROUTER_INSTRUCTIONS)] + [question])\n",
    "    # print(\"Processing user query...\")\n",
    "    user_query = json.loads(router_response.content)\n",
    "\n",
    "    if user_query.get(\"user_query\") == \"accept\":\n",
    "        # print(\"The user's query requires access to the database.\")\n",
    "        return \"accept\"\n",
    "    else:\n",
    "        # print(\"The user's query does not require access to the database.\")\n",
    "        return \"reject\"\n",
    "\n",
    "# Nodes\n",
    "def sql_agent(state):\n",
    "    '''Generate a SQL query based on the user question and executes it.\n",
    "    \n",
    "    Args:\n",
    "        state (State): The current state of the agent.\n",
    "        \n",
    "    Returns:\n",
    "        dict: The updated state with the tool call result appended to messages.'''\n",
    "\n",
    "    llm = ChatOllama(model=OLLAMA_MODEL, temperature=0, base_url=OLLAMA_BASE_URL)\n",
    "\n",
    "    # In this case, only one tool is present, so I am hardcoding it\n",
    "    # state['tools'] = StructuredTool object\n",
    "    llm_with_db = llm.bind_tools([executePostgreSQLQuery])\n",
    "\n",
    "    # Take the first message in the state to get the user question\n",
    "    question = state[\"messages\"][-1]\n",
    "\n",
    "    # The AIResponse containing the tool call and the sql query to be performed\n",
    "    sql_agent_response = llm_with_db.invoke([SystemMessage(content=SQL_AGENT_INSTRUCTIONS)] + [question])\n",
    "    \n",
    "    # print(\"Generating SQL query to execute...\")\n",
    "    # Execute the sql query and return the result\n",
    "    tool_call_result = executePostgreSQLQuery.invoke(sql_agent_response.tool_calls[0])\n",
    "    # print(f\"Executing SQL query: {sql_agent_response.tool_calls[0].get('args').get('query')} \")\n",
    "\n",
    "    return {\"tool_call_result\": tool_call_result}\n",
    "\n",
    "def generate_response(state):\n",
    "    '''Generate response to user query based on the context and user question.\n",
    "    \n",
    "    Args:\n",
    "        state (State): The current state of the agent.\n",
    "        \n",
    "    Returns:\n",
    "        dict: The updated state with the final response to the user query.'''\n",
    "\n",
    "    # Take the first message in the state to get the user question\n",
    "\n",
    "    question = state[\"messages\"][-1].content\n",
    "\n",
    "    # Get the tool call result from the state\n",
    "    tool_call_result = state[\"tool_call_result\"]\n",
    "    \n",
    "    # Format the system prompt sent to the llm with context and user question\n",
    "    rag_prompt_formatted = RAG_PROMPT.format(context=tool_call_result, question=question)\n",
    "\n",
    "    generate_response = llm.invoke([HumanMessage(content=rag_prompt_formatted)])\n",
    "\n",
    "    return {\"messages\": [generate_response]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x174ab6c5a90>"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow = StateGraph(State)\n",
    "\n",
    "workflow.add_node(\"sql_agent\", sql_agent)\n",
    "workflow.add_node(\"generate_response\", generate_response)\n",
    "\n",
    "workflow.set_conditional_entry_point(\n",
    "    router,\n",
    "    {\n",
    "        \"accept\": \"sql_agent\",\n",
    "        \"reject\": \"generate_response\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# should add like a max number of retries, if no go back to sql_agent\n",
    "workflow.add_conditional_edges(\n",
    "    \"generate_response\",\n",
    "    grader,\n",
    "    {\n",
    "        \"yes\": END,\n",
    "        \"no\": \"generate_response\"\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"sql_agent\", \"generate_response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpointer = MemorySaver()\n",
    "\n",
    "graph = workflow.compile(checkpointer=checkpointer)\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No results found.\n"
     ]
    }
   ],
   "source": [
    "print(tool_call_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "inputs = \"Hello, what is the price of the iphone 13 pro?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on our database, we have found information about the iPhone 13 Pro. Here are the details you requested:\n",
      "\n",
      "* Brand: Apple\n",
      "* Model: iPhone 13 Pro\n",
      "* Price: We currently have this model available for $999.\n",
      "\n",
      "As for availability, we do have stock of the iPhone 13 Pro in our stores. However, please note that prices and availability may vary depending on your location and other factors.\n",
      "\n",
      "Regarding storage and color options, I'm afraid we don't have that information readily available. If you're interested in purchasing this model, I recommend visiting our website or contacting one of our customer service representatives for more details.\n",
      "\n",
      "If you'd like to consider alternative models, we also have the iPhone 13 Mini available at a lower price point ($699). Would you like me to provide more information on that option?"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'llm_output'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[247], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m buffer \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      8\u001b[0m tool_msg_received \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m output, _ \u001b[38;5;129;01min\u001b[39;00m graph\u001b[38;5;241m.\u001b[39mastream(prompt, config, stream_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tool_msg_received:\n\u001b[0;32m     11\u001b[0m         buffer\u001b[38;5;241m.\u001b[39mappend(output)\n",
      "File \u001b[1;32mc:\\Users\\Aaron\\anaconda3\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2313\u001b[0m, in \u001b[0;36mPregel.astream\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[0;32m   2307\u001b[0m \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[0;32m   2308\u001b[0m \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates\u001b[39;00m\n\u001b[0;32m   2309\u001b[0m \u001b[38;5;66;03m# channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[0;32m   2310\u001b[0m \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[0;32m   2311\u001b[0m \u001b[38;5;66;03m# with channel updates applied only at the transition between steps\u001b[39;00m\n\u001b[0;32m   2312\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[1;32m-> 2313\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39matick(\n\u001b[0;32m   2314\u001b[0m         loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[0;32m   2315\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[0;32m   2316\u001b[0m         retry_policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_policy,\n\u001b[0;32m   2317\u001b[0m         get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[0;32m   2318\u001b[0m     ):\n\u001b[0;32m   2319\u001b[0m         \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[0;32m   2320\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m output():\n\u001b[0;32m   2321\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m o\n",
      "File \u001b[1;32mc:\\Users\\Aaron\\anaconda3\\Lib\\site-packages\\langgraph\\pregel\\runner.py:527\u001b[0m, in \u001b[0;36mPregelRunner.atick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[0;32m    525\u001b[0m     fut\u001b[38;5;241m.\u001b[39mcancel()\n\u001b[0;32m    526\u001b[0m \u001b[38;5;66;03m# panic on failure or timeout\u001b[39;00m\n\u001b[1;32m--> 527\u001b[0m _panic_or_proceed(\n\u001b[0;32m    528\u001b[0m     futures\u001b[38;5;241m.\u001b[39mdone\u001b[38;5;241m.\u001b[39munion(f \u001b[38;5;28;01mfor\u001b[39;00m f, t \u001b[38;5;129;01min\u001b[39;00m futures\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m t \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    529\u001b[0m     timeout_exc_cls\u001b[38;5;241m=\u001b[39masyncio\u001b[38;5;241m.\u001b[39mTimeoutError,\n\u001b[0;32m    530\u001b[0m     panic\u001b[38;5;241m=\u001b[39mreraise,\n\u001b[0;32m    531\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Aaron\\anaconda3\\Lib\\site-packages\\langgraph\\pregel\\runner.py:619\u001b[0m, in \u001b[0;36m_panic_or_proceed\u001b[1;34m(futs, timeout_exc_cls, panic)\u001b[0m\n\u001b[0;32m    617\u001b[0m         \u001b[38;5;66;03m# raise the exception\u001b[39;00m\n\u001b[0;32m    618\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m panic:\n\u001b[1;32m--> 619\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m    620\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inflight:\n\u001b[0;32m    621\u001b[0m     \u001b[38;5;66;03m# if we got here means we timed out\u001b[39;00m\n\u001b[0;32m    622\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m inflight:\n\u001b[0;32m    623\u001b[0m         \u001b[38;5;66;03m# cancel all pending tasks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Aaron\\anaconda3\\Lib\\site-packages\\langgraph\\pregel\\retry.py:128\u001b[0m, in \u001b[0;36marun_with_retry\u001b[1;34m(task, retry_policy, stream, configurable)\u001b[0m\n\u001b[0;32m    126\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 128\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m task\u001b[38;5;241m.\u001b[39mproc\u001b[38;5;241m.\u001b[39mainvoke(task\u001b[38;5;241m.\u001b[39minput, config)\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    130\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[1;32mc:\\Users\\Aaron\\anaconda3\\Lib\\site-packages\\langgraph\\utils\\runnable.py:585\u001b[0m, in \u001b[0;36mRunnableSeq.ainvoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    583\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m step\u001b[38;5;241m.\u001b[39mainvoke(\u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    584\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 585\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m step\u001b[38;5;241m.\u001b[39mainvoke(\u001b[38;5;28minput\u001b[39m, config)\n\u001b[0;32m    586\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m    587\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\Aaron\\anaconda3\\Lib\\site-packages\\langgraph\\utils\\runnable.py:371\u001b[0m, in \u001b[0;36mRunnableCallable.ainvoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ASYNCIO_ACCEPTS_CONTEXT:\n\u001b[0;32m    370\u001b[0m     coro \u001b[38;5;241m=\u001b[39m cast(Coroutine[\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, Any], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n\u001b[1;32m--> 371\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mcreate_task(coro, context\u001b[38;5;241m=\u001b[39mcontext)\n\u001b[0;32m    372\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    373\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Aaron\\anaconda3\\Lib\\site-packages\\langgraph\\graph\\branch.py:191\u001b[0m, in \u001b[0;36mBranch._aroute\u001b[1;34m(self, input, config, reader, writer)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    190\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\n\u001b[1;32m--> 191\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mainvoke(value, config)\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_finish(writer, \u001b[38;5;28minput\u001b[39m, result, config)\n",
      "File \u001b[1;32mc:\\Users\\Aaron\\anaconda3\\Lib\\site-packages\\langgraph\\utils\\runnable.py:359\u001b[0m, in \u001b[0;36mRunnableCallable.ainvoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    357\u001b[0m coro \u001b[38;5;241m=\u001b[39m cast(Coroutine[\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, Any], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ASYNCIO_ACCEPTS_CONTEXT:\n\u001b[1;32m--> 359\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mcreate_task(coro, context\u001b[38;5;241m=\u001b[39mcontext)\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    361\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m coro\n",
      "File \u001b[1;32mc:\\Users\\Aaron\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\config.py:588\u001b[0m, in \u001b[0;36mrun_in_executor\u001b[1;34m(executor_or_config, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    584\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[0;32m    586\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m executor_or_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(executor_or_config, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    587\u001b[0m     \u001b[38;5;66;03m# Use default executor with context copied from current context\u001b[39;00m\n\u001b[1;32m--> 588\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mget_running_loop()\u001b[38;5;241m.\u001b[39mrun_in_executor(\n\u001b[0;32m    589\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    590\u001b[0m         cast(Callable[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, T], partial(copy_context()\u001b[38;5;241m.\u001b[39mrun, wrapper)),\n\u001b[0;32m    591\u001b[0m     )\n\u001b[0;32m    593\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mget_running_loop()\u001b[38;5;241m.\u001b[39mrun_in_executor(executor_or_config, wrapper)\n",
      "File \u001b[1;32mc:\\Users\\Aaron\\anaconda3\\Lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[1;32mc:\\Users\\Aaron\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\config.py:579\u001b[0m, in \u001b[0;36mrun_in_executor.<locals>.wrapper\u001b[1;34m()\u001b[0m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 579\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    581\u001b[0m         \u001b[38;5;66;03m# StopIteration can't be set on an asyncio.Future\u001b[39;00m\n\u001b[0;32m    582\u001b[0m         \u001b[38;5;66;03m# it raises a TypeError and leaves the Future pending forever\u001b[39;00m\n\u001b[0;32m    583\u001b[0m         \u001b[38;5;66;03m# so we need to convert it to a RuntimeError\u001b[39;00m\n\u001b[0;32m    584\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[242], line 23\u001b[0m, in \u001b[0;36mgrader\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m     20\u001b[0m tool_call_result \u001b[38;5;241m=\u001b[39m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_call_result\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Format the system prompt sent to the llm with context from the database and user question\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m grader_prompt_formatted \u001b[38;5;241m=\u001b[39m GRADER_PROMPT\u001b[38;5;241m.\u001b[39mformat(data\u001b[38;5;241m=\u001b[39mtool_call_result, question\u001b[38;5;241m=\u001b[39mquestion)\n\u001b[0;32m     25\u001b[0m grader_response \u001b[38;5;241m=\u001b[39m llm_json\u001b[38;5;241m.\u001b[39minvoke([SystemMessage(content\u001b[38;5;241m=\u001b[39mGRADER_INSTRUCTIONS)] \u001b[38;5;241m+\u001b[39m [HumanMessage(content\u001b[38;5;241m=\u001b[39mgrader_prompt_formatted)])\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# print(\"Grading the results from the database...\")\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'llm_output'",
      "\u001b[0mDuring task with name 'generate_response' and id '65940cb3-3264-5aa4-fdd6-d323eea4ea0a'"
     ]
    }
   ],
   "source": [
    "prompt = {\n",
    "    \"messages\": [HumanMessage(content=inputs)],\n",
    "    \"tool_call_result\": []\n",
    "    }\n",
    "config = {\"configurable\": {\"thread_id\": \"12344\"}}\n",
    "\n",
    "buffer = []\n",
    "tool_msg_received = False\n",
    "async for output, _ in graph.astream(prompt, config, stream_mode=\"messages\"):\n",
    "    if not tool_msg_received:\n",
    "        buffer.append(output)\n",
    "        if isinstance(output, ToolMessage):\n",
    "            tool_msg_received = True\n",
    "            buffer.clear()\n",
    "    else:\n",
    "        # After the ToolMessage, print tokens directly.\n",
    "        print(output.content, end='', flush=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
